{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainFeatureGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs79bPmmXTa4",
        "colab_type": "text"
      },
      "source": [
        "This notebook is for feature generation of training data. This needs all the five  raw csv's of training data given from the KDD. We put the data generated in each cell(each feature extraction), into a new csv. Finally, all generated csv's are merged to form a final csv.\n",
        "\n",
        "For the purpose of testing the model, we have **attached the Final generated csv** which can be used to train and test the model. Generation of these individual features takes lot of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajgJp5VU0Qkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwHnucSD2wrh",
        "colab_type": "code",
        "outputId": "deb5706d-de45-4336-c8a0-474b44843479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "cmd_string = 'git clone https://github.com/srivathsa-rao/MOOC-Dropout-Prediction.git MLProject'\n",
        "\n",
        "os.system(cmd_string)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UExdD8vh0Zmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/MLProject/submissions/originalData')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwraAk-34v1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf train.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUGD9qFe5H80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/MLProject/submissions/originalData/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_wbTGm5Tit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-0z9CN-5XzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vSibwb80WHd",
        "colab_type": "code",
        "outputId": "67bcbe94-92aa-4d50-b71c-8d5b43cb7088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MLProject/submissions/originalData/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cMj5EWg2gHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training data\n",
        "\n",
        "object_data = pd.read_csv('object.csv')\n",
        "dates_data = pd.read_csv('date.csv')\n",
        "\n",
        "log_data = pd.read_csv('log_train.csv')\n",
        "enrollment_data = pd.read_csv('enrollment_train.csv')\n",
        "\n",
        "truth_data = pd.read_csv('truth_train.csv', names=['enrollment_id', 'label'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0u-j8Zb_Tj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"Columns in object data is :{}\".format(object_data.columns))\n",
        "print(\"Columns in date data is :{}\".format(dates_data.columns))\n",
        "\n",
        "print(\"Columns in log data is :{}\".format(log_data.columns))\n",
        "print(\"Columns in enrollment data is :{}\".format(enrollment_data.columns))\n",
        "\n",
        "print(\"Columns in truth data is :{}\".format(truth_data.columns))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MnW5c5hWRK_",
        "colab_type": "text"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkky64uqRv9h",
        "colab_type": "text"
      },
      "source": [
        "We have extraced the number of course the user has enrolled in from the enrollment data. This has been extracted with the intention that the number of courses of an user will have impact on whether the user completes or drops a particular course.\n",
        "\n",
        "The results are stored as part of - 'number_of_course.csv'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkfv9rCx7iFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gives number of course taken by each user.\n",
        "# no need to handle any data imputations.\n",
        "username = []\n",
        "number_of_course = []\n",
        "\n",
        "for i in range(enrollment_data.shape[0]):\n",
        "    if enrollment_data['username'][i] not in username:\n",
        "        username.append(enrollment_data['username'][i])\n",
        "        number_of_course.append(enrollment_data[enrollment_data['username'] == enrollment_data['username'][i]].shape[0])\n",
        "\n",
        "user_course = pd.DataFrame({'username':username,'number_of_course':number_of_course})\n",
        "\n",
        "parallel_courses = user_course.merge(enrollment_data, left_on='username', right_on='username', how='inner')[['enrollment_id', 'number_of_course']]\n",
        "\n",
        "parallel_courses.to_csv('generated/number_of_course.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxIZxygz6fyY",
        "colab_type": "text"
      },
      "source": [
        "We have extracted parallel enrollments of every user. If a user is enrolled in more courses simulataneously, the probability that he completes all his courses might be low and vice-versa. So, this might have impact on the decision of whether an user will drop or complete the course.\n",
        "\n",
        "Extracted feature is stored in - parallel_enrollments.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld5FLq7419w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to fetch parallel enrollments...\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "username = []\n",
        "number_of_course = []\n",
        "\n",
        "def interval_overlaps(a, b):\n",
        "  return min(a['to'], b['to']) - max(a['from'], b['from']) > np.timedelta64(0)\n",
        "\n",
        "\n",
        "def count_overlaps(df1):\n",
        "  #print(df1)\n",
        "  return pd.Series([df1.apply(lambda x: interval_overlaps(x, df1.iloc[i]), axis=1).sum() - 1 for i in range(len(df1))], df1.index)\n",
        "\n",
        "def get_parallel_enrollment_cnt(course_id_data_frame):\n",
        "  if len(course_id_data_frame) < 2:\n",
        "    return 0\n",
        "  df = dates_data.loc[dates_data['course_id'].isin(course_id_data_frame)]\n",
        "  df['from'] = pd.to_datetime(df['from']) \n",
        "  df['to'] = pd.to_datetime(df['to'])\n",
        "  overlap_list = df.groupby([True]*len(df)).apply(count_overlaps).values[0]\n",
        "  if sum(overlap_list) == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return sum(overlap_list)//np.count_nonzero(np.array(overlap_list))\n",
        "\n",
        "for i in range(enrollment_data.shape[0]):\n",
        "    if enrollment_data['username'][i] not in username:\n",
        "        username.append(enrollment_data['username'][i])\n",
        "        user_df = enrollment_data.loc[enrollment_data['username'] == username[-1]]\n",
        "        number_of_course.append(get_parallel_enrollment_cnt(user_df['course_id']))\n",
        "    \n",
        "\n",
        "user_course = pd.DataFrame({'username':username,'parallel_enrollments':number_of_course})\n",
        "\n",
        "parallel_courses = user_course.merge(enrollment_data, left_on='username', right_on='username', how='inner')[['enrollment_id', 'parallel_enrollments']]\n",
        "\n",
        "parallel_courses.to_csv('generated/parallel_enrollments.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdjCFn6WW75U",
        "colab_type": "text"
      },
      "source": [
        "We have extracted number of users who have enrolled in a particular course. If a course is interesting or popular, there might be more enrollments and this would result in more completion. On the contrary, if the course is challenging, it might have less enrollments and more drop outs among the enrolled students.\n",
        "\n",
        "Th extracted data is stored in - number_of_users_per_course.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx9LUPCkBWhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gives number of users taken the same course. Merge this with the enrollment.\n",
        "# no need to handle any data imputations.\n",
        "course_id = []\n",
        "number_of_users = []\n",
        "\n",
        "for course in enrollment_data['course_id'].unique():\n",
        "  course_id.append(course)\n",
        "  number_of_users.append(len(enrollment_data[enrollment_data['course_id'] == course]))\n",
        "\n",
        "number_of_enrollments_per_course = pd.DataFrame({'course_id':course_id,'number_of_users_in_course':number_of_users})\n",
        "\n",
        "merge_enrollments_with_course = enrollment_data.merge(number_of_enrollments_per_course, left_on='course_id', right_on='course_id', how='inner')[['enrollment_id', 'number_of_users_in_course']]\n",
        "merge_enrollments_with_course.to_csv('generated/number_of_users_per_course.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-mQ3UhyZI_v",
        "colab_type": "text"
      },
      "source": [
        "The number of modules in the enrolled course which the user has accessed is deduced from the enrollment and log_train csv. This might have an impact on whether a student drops the course or completes course. Higher the number of modules accessed per course might have positive impact toward the completion of the course.\n",
        "\n",
        "The extracted data is stored in - number_of_module.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpkUL55I7QI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of module accessed\n",
        "# no need to handle any data imputations.\n",
        "enrollment_id = []\n",
        "number_of_module = []\n",
        "\n",
        "for enrollment in log_data['enrollment_id'].unique():\n",
        "  enr = log_data[log_data['enrollment_id'] == enrollment]\n",
        "  number_of_objects_enr =  len(enr['object'].unique())\n",
        "  enrollment_id.append(enrollment)\n",
        "  number_of_module.append(number_of_objects_enr)\n",
        "\n",
        "number_of_objects = pd.DataFrame({'enrollment_id':enrollment_id,'number_of_module':number_of_module})\n",
        "number_of_objects.to_csv('generated/number_of_module.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AaBVAiLE4XS",
        "colab_type": "text"
      },
      "source": [
        "This feature is an extension of the feature extracted in number_of_module.csv. This generates the percentage of module accessed by the user in a course.\n",
        "This might show the level of interest of the student toward the course.\n",
        "\n",
        "Extracted feature is stored in percentage_of_module.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdYELWkRr8Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Percentage of module accessed\n",
        "# no need to handle any data imputations.\n",
        "enrollment_id = []\n",
        "percentage_of_module = []\n",
        "\n",
        "modules_per_course = {}\n",
        "\n",
        "for course in object_data['course_id'].unique():\n",
        "  course_data_in_object_data = object_data[object_data['course_id'] == course]\n",
        "  course_data_in_object_data = course_data_in_object_data.dropna(subset=['children'])\n",
        "  number_of_module_in_course = len(course_data_in_object_data['module_id'].unique())\n",
        "\n",
        "  modules_per_course[course] = number_of_module_in_course\n",
        "\n",
        "\n",
        "for enrollment in log_data['enrollment_id'].unique():\n",
        "  enr = log_data[log_data['enrollment_id'] == enrollment]\n",
        "  number_of_objects_enr =  len(enr['object'].unique())\n",
        "  number_of_modules_in_course = modules_per_course[enrollment_data[enrollment_data['enrollment_id'] == enrollment].course_id.values[0]]\n",
        "  enrollment_id.append(enrollment)\n",
        "  percentage_of_module.append(number_of_objects_enr/number_of_modules_in_course)\n",
        "\n",
        "percentage_of_objects = pd.DataFrame({'enrollment_id':enrollment_id,'percentage_of_module':percentage_of_module})\n",
        "percentage_of_objects.to_csv('generated/percentage_of_module.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6tThAoAFU20",
        "colab_type": "text"
      },
      "source": [
        "We have extracted time spent on each browser or server event by the user in the course. This helps us to analyse the amount of time a user spends in accessing each course.\n",
        "\n",
        "\n",
        "There are lot of things student can perform on a course like watcihng course video, doing an assignment etc. We have extracted the time spent by the user (browser) and the server on each kind of event on modules of the courses.\n",
        "This is extracted based on the assumption that consecutive events timestamp can be used to generate the time spent on the 1st event.\n",
        "\n",
        "Extracted data is stored in - time_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeFCCvJH8zob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time duration spent on each event by the user in the course!\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "\n",
        "\n",
        "event_data_frame = pd.DataFrame(np.zeros((enrollment_data.shape[0],15)), columns = ['enrollment_id','time_access_browser','time_access_server','time_navigate_browser','time_navigate_server','time_problem_browser','time_problem_server','time_page_close_server','time_page_close_browser','time_video_server','time_video_browser','time_discussion_server','time_discussion_browser','time_wiki_server','time_wiki_browser'])\n",
        "event_data_frame[\"enrollment_id\"] = enrollment_data[\"enrollment_id\"]\n",
        "\n",
        "enrollment_index = 0\n",
        "last_seen_enrollment = log_data[\"enrollment_id\"][0]\n",
        "\t\n",
        "data_frame = event_data_frame.to_dict()\n",
        "\n",
        "for i in range(log_data.shape[0] -1):\n",
        "  enrollment_id = log_data[\"enrollment_id\"][i]\n",
        "  \n",
        "  if enrollment_id != last_seen_enrollment:\n",
        "    enrollment_index += 1\n",
        "    last_seen_enrollment = enrollment_id\n",
        "  \n",
        "  event = log_data[\"event\"][i]\n",
        "  source = log_data[\"source\"][i]\n",
        "\n",
        "  if log_data[\"enrollment_id\"][i+1] == log_data[\"enrollment_id\"][i] :\n",
        "    time_spent = (parse(log_data[\"time\"][i+1]) - parse(log_data[\"time\"][i])).total_seconds()\n",
        "    if  time_spent < 7200:\n",
        "      time_span = time_spent\n",
        "    else:\n",
        "      time_span = 0\n",
        "\n",
        "  event_type = \"time_\"+event+\"_\"+source\n",
        "  data_frame[event_type][enrollment_index] += time_span\n",
        "\n",
        "event_data_frame = pd.DataFrame.from_dict(data_frame)\n",
        "event_data_frame.to_csv('generated/time_data_old.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxlhVYpdsgbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_data = pd.read_csv('generated/time_data_old.csv')\n",
        "#time_data.columns\n",
        "\n",
        "# del time_data['time_navigate_browser']\n",
        "# del time_data['time_discussion_browser']\n",
        "# del time_data['time_page_close_server']\n",
        "# del time_data['time_wiki_browser']\n",
        "# del time_data['time_video_server']\n",
        "\n",
        "time_data.to_csv('generated/time_data.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN8FlIgXGT-u",
        "colab_type": "text"
      },
      "source": [
        "If a user regularly spends more time on a course, it helps us to infer that the user will complete the course and vice-versa. So, we have also extracted the number of logs which are less than 60 seconds in any event. \n",
        "\n",
        "\n",
        "This is in extension to the time related feature generated above. This shows the count of time bursts on the events which are less than one minute. Students wouldn't have done anything significant in a minute on a module. More number of such events might have an negative impact on the completion of the course.\n",
        "\n",
        "Extracted data is stored in the - time_data_60.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iln1Lz5JifZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of logs less than 60 seconds on any event\n",
        "\n",
        "event_data_frame = pd.DataFrame(np.zeros((enrollment_data.shape[0],15)), columns = ['enrollment_id','count_access_browser','count_access_server','count_navigate_browser','count_navigate_server','count_problem_browser','count_problem_server','count_page_close_server','count_page_close_browser','count_video_server','count_video_browser','count_discussion_server','count_discussion_browser','count_wiki_server','count_wiki_browser'])\n",
        "event_data_frame[\"enrollment_id\"] = enrollment_data[\"enrollment_id\"]\n",
        "\n",
        "enrollment_index = 0\n",
        "last_seen_enrollment = log_data[\"enrollment_id\"][0]\n",
        "\t\n",
        "data_frame = event_data_frame.to_dict()\n",
        "\n",
        "for i in range(log_data.shape[0] -1):\n",
        "  enrollment_id = log_data[\"enrollment_id\"][i]\n",
        "  \n",
        "  if enrollment_id != last_seen_enrollment:\n",
        "    enrollment_index += 1\n",
        "    last_seen_enrollment = enrollment_id\n",
        "  \n",
        "  event = log_data[\"event\"][i]\n",
        "  source = log_data[\"source\"][i]\n",
        "\n",
        "  if log_data[\"enrollment_id\"][i+1] == log_data[\"enrollment_id\"][i] :\n",
        "    time_spent = (parse(log_data[\"time\"][i+1]) - parse(log_data[\"time\"][i])).total_seconds()\n",
        "    if time_spent < 60:\n",
        "      event_type = \"count_\"+event+\"_\"+source\n",
        "      data_frame[event_type][enrollment_index] += 1\n",
        "\n",
        "event_data_frame = pd.DataFrame.from_dict(data_frame)\n",
        "event_data_frame.to_csv('generated/time_data_60_old.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa27cHLe6K3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "event_data_frame = pd.read_csv('generated/time_data_60_old.csv')\n",
        "event_data_frame.columns\n",
        "# del event_data_frame['count_navigate_browser']\n",
        "# del event_data_frame['count_discussion_browser']\n",
        "# del event_data_frame['count_page_close_server']\n",
        "# del event_data_frame['count_wiki_browser']\n",
        "# del event_data_frame['count_video_server']\n",
        "\n",
        "event_data_frame.to_csv('generated/time_data_60.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5QNTWc8G8_1",
        "colab_type": "text"
      },
      "source": [
        "The number of days every student spends on the modules of the enrolled course is an important criteria to predict the completion of the coursework. If a student is least interested, he might spend less number of days on the course and vice-versa.\n",
        "We have extracted this data from the log_data and enrollment.\n",
        "\n",
        "Extracted data is stored in - active_days.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkiD-yOBc8-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fetch the number of active days for each enrollment\n",
        "import time\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "\n",
        "enrollments = []\n",
        "active_days = []\n",
        "\n",
        "for enrollment in log_data['enrollment_id'].unique():\n",
        "  number_of_active_days = pd.to_datetime(log_data[log_data['enrollment_id'] == enrollment]['time']).dt.date.unique().shape[0]\n",
        "  print(\"Enrollment ID :{}\".format(enrollment))\n",
        "  enrollments.append(enrollment)\n",
        "  active_days.append(number_of_active_days)\n",
        "\n",
        "\n",
        "number_of_active_day = pd.DataFrame({'enrollment_id':enrollments,'active_days':active_days})\n",
        "number_of_active_day.to_csv('generated/active_days.csv', index=False)\n",
        "# merge_enrollments_with_course.to_csv('train/completion_rate_for_courses.csv', index='False')\n",
        "\n",
        "#local_enrollment[\"time\"].map(lambda t: t.date()).unique()\n",
        "#pd.to_datetime(local_enrollment['time']).dt.date.unique().shape[0]\n",
        "#number_of_active_day\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smkPJYVnQbNu",
        "colab_type": "text"
      },
      "source": [
        "Access of modules by students on the enrolled courses in every week of course can help in knowing the access pattern of the students. High number of access of the modules in all weeks would result in low drop rate for the course. \n",
        "\n",
        "The extracted data is stored in - wk_cnts.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u9YJSom2Aww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to fetch activities in weeks....\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "dates_data['from'] = pd.to_datetime(dates_data['from'])\n",
        "dates_data['to'] = pd.to_datetime(dates_data['to'])\n",
        "log_data['time'] = pd.to_datetime(log_data['time'])\n",
        "\n",
        "enrollment_ids = []\n",
        "week_activity_count = [[],[],[],[], []]\n",
        "\n",
        "def append_wk_counts(start_from, time_values):\n",
        "  start_date = start_from\n",
        "  end_date = start_date + pd.Timedelta(timedelta(days = 7))\n",
        "  for i in range(5):\n",
        "    week_activity_count[i].append(np.sum((start_date <= time_values) & (end_date > time_values), axis =0 ))\n",
        "    start_date = end_date\n",
        "    end_date = start_date + pd.Timedelta(timedelta(days = 7))\n",
        "  \n",
        "\n",
        "for i in range(enrollment_data.shape[0]):\n",
        "    enrollment_ids.append(enrollment_data['enrollment_id'][i])\n",
        "    start_end = dates_data.loc[dates_data['course_id'] == enrollment_data['course_id'][i]][['from','to']]\n",
        "    time_values = log_data.loc[log_data['enrollment_id'] == enrollment_data['enrollment_id'][i]]['time']\n",
        "    append_wk_counts(start_end['from'].values, time_values.values)\n",
        "\n",
        "\n",
        "wk_cnts= pd.DataFrame({'enrollment_id':enrollment_ids,'week1_activity_count':week_activity_count[0], 'week2_activity_count':week_activity_count[1], 'week3_activity_count':week_activity_count[2], 'week4_activity_count':week_activity_count[3], 'week5_activity_count':week_activity_count[4]})\n",
        "\n",
        "wk_cnts_csv = wk_cnts.merge(enrollment_data, left_on='enrollment_id', right_on='enrollment_id', how='inner')[['enrollment_id', 'week1_activity_count', 'week2_activity_count', 'week3_activity_count','week4_activity_count', 'week5_activity_count']]\n",
        "\n",
        "wk_cnts_csv.to_csv('generated/wk_cnts.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVm7LvL0m26v",
        "colab_type": "text"
      },
      "source": [
        "The number of 30 minute user sessions doing different activities on the course modules. Large number of access means, high interest and may result in completion of course.\n",
        "\n",
        "The extracted data is stored in - wk_session_cnts.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX1pRV9prYS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get sessions count..\n",
        "#activities \n",
        "\n",
        "#Code to fetch activities in weeks....\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "dates_data['from'] = pd.to_datetime(dates_data['from'])\n",
        "dates_data['to'] = pd.to_datetime(dates_data['to'])\n",
        "log_data['time'] = pd.to_datetime(log_data['time'])\n",
        "\n",
        "enrollment_ids = []\n",
        "week_session_count = [[],[],[],[], []]\n",
        "daily_activity_count = [[] for i in range(30)]\n",
        "\n",
        "def give_number_of_sessions_in_week(start_from, time_values, end_time):\n",
        "  \n",
        "  # print(\"start time of event in week\", start_from)\n",
        "  # print(\"End time of event in week\", end_time)\n",
        "\n",
        "  start_date = start_from\n",
        "  end_date = start_date + pd.Timedelta(timedelta(minutes= 30))\n",
        "\n",
        "  # print(\"end date 2\", end_date)\n",
        "  session_count = 0\n",
        "  # print(end_time)\n",
        "  while end_date < end_time:\n",
        "    condition = (pd.to_datetime(start_date) <= time_values) & (pd.to_datetime(end_date) > time_values)\n",
        "    events = np.extract(condition, time_values)\n",
        "\n",
        "    number_of_events = len(events)\n",
        "    #print(number_of_events)\n",
        "\n",
        "    if number_of_events >= 1:\n",
        "      session_count += 1\n",
        "    \n",
        "    start_date = end_date\n",
        "    end_date = start_date + pd.Timedelta(timedelta(minutes= 30))\n",
        "  return session_count\n",
        "    \n",
        "\n",
        "def append_wk_counts(start_from, time_values):\n",
        "\n",
        "  #print(\"start_from 1\", start_from)\n",
        "  start_date = start_from\n",
        "  end_date = start_date + pd.Timedelta(timedelta(days = 7))\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    number_of_session_in_week = 0\n",
        "\n",
        "    condition = (start_date <= time_values) & (end_date > time_values)\n",
        "\n",
        "    events = np.extract(condition, time_values)\n",
        "    #print(len(events))\n",
        "    if len(events) > 0:\n",
        "      number_of_session_in_week = give_number_of_sessions_in_week(np.array(events[0]), pd.to_datetime(events), end_date[0])\n",
        "    else:\n",
        "       number_of_session_in_week = 0\n",
        "    #number_of_session_in_week = len(events)\n",
        "    week_session_count[i].append(number_of_session_in_week)\n",
        "    start_date = end_date\n",
        "    end_date = start_date + pd.Timedelta(timedelta(days = 7))\n",
        "    #print(events)\n",
        "  \n",
        "\n",
        "for i in range(enrollment_data.shape[0]):\n",
        "    enrollment_ids.append(enrollment_data['enrollment_id'][i])\n",
        "    start_end = dates_data.loc[dates_data['course_id'] == enrollment_data['course_id'][i]][['from','to']]\n",
        "    time_values = log_data.loc[log_data['enrollment_id'] == enrollment_data['enrollment_id'][i]]['time']\n",
        "    append_wk_counts(start_end['from'].values, time_values.values)\n",
        "    print(\"enrollment id:\", i)\n",
        "\n",
        "\n",
        "wk_cnts= pd.DataFrame({'enrollment_id':enrollment_ids,'week1_session_count':week_session_count[0], 'week2_session_count':week_session_count[1], 'week3_session_count':week_session_count[2], 'week4_session_count':week_session_count[3], 'week5_session_count':week_session_count[4]})\n",
        "\n",
        "wk_cnts_csv = wk_cnts.merge(enrollment_data, left_on='enrollment_id', right_on='enrollment_id', how='inner')[['enrollment_id', 'week1_session_count', 'week2_session_count', 'week3_session_count','week4_session_count', 'week5_session_count']]\n",
        "wk_cnts_csv.to_csv('generated/wk_session_cnts.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVdeTSFBnuXd",
        "colab_type": "text"
      },
      "source": [
        "Activity count of user on a daily basis on the modules of the course. This helps to know the active days of the user for the duration of 30 days i.e the course duration.\n",
        "\n",
        "Extracted data is stored in - generated/daily_cnts.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlK7wUdMuqEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code for generating days in activity\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "dates_data['from'] = pd.to_datetime(dates_data['from'])\n",
        "dates_data['to'] = pd.to_datetime(dates_data['to'])\n",
        "log_data['time'] = pd.to_datetime(log_data['time'])\n",
        "enrollment_ids = []\n",
        "daily_activity_count = [[] for i in range(30)]\n",
        "\n",
        "def append_wk_counts(start_from, time_values):\n",
        "  start_date = start_from\n",
        "  end_date = start_date + pd.Timedelta(timedelta(days = 1))\n",
        "  for i in range(30):\n",
        "    daily_activity_count[i].append(np.sum((start_date <= time_values) & (end_date > time_values), axis =0 ))\n",
        "    start_date = end_date\n",
        "    end_date = start_date + pd.Timedelta(timedelta(days = 1))\n",
        "  \n",
        "\n",
        "for i in range(enrollment_data.shape[0]):\n",
        "    enrollment_ids.append(enrollment_data['enrollment_id'][i])\n",
        "    start_end = dates_data.loc[dates_data['course_id'] == enrollment_data['course_id'][i]][['from','to']]\n",
        "    time_values = log_data.loc[log_data['enrollment_id'] == enrollment_data['enrollment_id'][i]]['time']\n",
        "    append_wk_counts(start_end['from'].values, time_values.values)\n",
        "\n",
        "\n",
        "dict_to_csv = {'day{0}_activity_count'.format(i+1):activity for i, activity in enumerate(daily_activity_count)}\n",
        "dict_to_csv['enrollment_id'] = enrollment_ids\n",
        "daily_cnts= pd.DataFrame(dict_to_csv)\n",
        "\n",
        "daily_cnts_csv = daily_cnts.merge(enrollment_data, left_on='enrollment_id', right_on='enrollment_id', how='inner')[dict_to_csv.keys()]\n",
        "\n",
        "daily_cnts_csv.to_csv('generated/daily_cnts.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Rj6ildUUbq",
        "colab_type": "text"
      },
      "source": [
        "Extracted the count of the access of different modules in a course by the students. Higher the access of modules in different categories might result in high completion rate.\n",
        "\n",
        "Extracted data is stored in - extracted_category.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igZyC0vxlBfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetch category data for each log..\n",
        "\n",
        "log_object_merge = log_data.merge(object_data, left_on='object', right_on='module_id', how='inner')\n",
        "df_category = pd.DataFrame(np.zeros((enrollment_data.shape[0],16)), columns=['enrollment_id','about','chapter','course','course_info','html','outlink','problem','sequential','static_tab','vertical','video','combinedopenended','peergrading','discussion','dictation'])\n",
        "df_category[\"enrollment_id\"] = enrollment_data[\"enrollment_id\"]\n",
        "\n",
        "\n",
        "last_enrollment = df_category['enrollment_id'][0]\n",
        "df_category_index = 0\n",
        "\n",
        "df_category = df_category.to_dict()\n",
        "\n",
        "sorted_log_object_merge = log_object_merge.sort_values(by=['enrollment_id'],ignore_index=True)\n",
        "\n",
        "for i in range(sorted_log_object_merge.shape[0] -1 ):\n",
        "  enrollment_id = sorted_log_object_merge['enrollment_id'][i]\n",
        "\n",
        "  if enrollment_id != last_enrollment:\n",
        "    df_category_index += 1\n",
        "    last_enrollment = enrollment_id\n",
        "\n",
        "  category_ = sorted_log_object_merge['category'][i]\n",
        "  df_category[category_][df_category_index] += 1\n",
        "\n",
        "\n",
        "df = pd.DataFrame.from_dict(df_category)\n",
        "df.to_csv('generated/extracted_category.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPv3KaWxn-US",
        "colab_type": "text"
      },
      "source": [
        "The data of each of the 39 courses which students can enroll. This will help us know the course which has more enrollments, which might have impact on the number of students completing the course.\n",
        "\n",
        "Extracted data is stored in - encoded_course.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hhs8uQ8fOXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding courses.\n",
        "encoded_courses= pd.get_dummies(enrollment_data['course_id'], prefix = 'course')\n",
        "encoded_enrollment = pd.concat([enrollment_data[['enrollment_id']], encoded_courses], axis=1)\n",
        "\n",
        "encoded_enrollment.to_csv('generated/encoded_course.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV2MZza7ogDr",
        "colab_type": "text"
      },
      "source": [
        "Based on the prior data, we are trying to fetch the percentage of completion of any given course. This would help us determine the likelihood of completion of the course for the future as well.\n",
        "\n",
        "Extracted data is stored in - completion_rate_for_courses.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyuRBd5dPTcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#do not run for test data - as this is extracted in a different way for test\n",
        "\n",
        "# Find the success rate of each course \n",
        "# no need to handle any data imputations.\n",
        "enrollment_label_merge = enrollment_data.merge(truth_data, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "courses = []\n",
        "completions = []\n",
        "\n",
        "for course in enrollment_label_merge['course_id'].unique():\n",
        "  course_enrollment_data = enrollment_label_merge[enrollment_label_merge['course_id'] == course]\n",
        "  total = course_enrollment_data.shape[0]\n",
        "  completion = len(course_enrollment_data[course_enrollment_data['label'] == 0]) # 0 is success\n",
        "  completion_rate = (completion/total) * 100\n",
        "\n",
        "  courses.append(course)\n",
        "  completions.append(completion_rate)\n",
        "\n",
        "course_completion_rate = pd.DataFrame({'course_id':courses,'overall_course_completion_rate':completions})\n",
        "merge_enrollments_with_completions = enrollment_data.merge(course_completion_rate, left_on='course_id', right_on='course_id', how='inner')[['enrollment_id', 'overall_course_completion_rate']]\n",
        "merge_enrollments_with_completions.to_csv('generated/completion_rate_for_courses.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptp8ji5lsYEI",
        "colab_type": "text"
      },
      "source": [
        "Based on the prior data, we extract the course completion rate of each users of their courses. This would help us understand the trend of each user course completion and drop outs.\n",
        "\n",
        "Extracted data is strored in - individual_completion_rate.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZgetFgRZv6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get success rate for individual enrollments\n",
        "\n",
        "# do not run for test data - as this is extracted in a different way for test\n",
        "\n",
        "number_of_users = len(enrollment_data['username'].unique())\n",
        "enrollment_truth_merge = enrollment_data.merge(truth_data, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "df_total_usernames = pd.DataFrame(np.zeros((number_of_users,4)), columns=['username','total_enrollments','drop_rate', 'completion_rate'])\n",
        "count = 0\n",
        "for user in enrollment_truth_merge['username'].unique():\n",
        "  user_pd = enrollment_truth_merge[enrollment_truth_merge['username'] == user]\n",
        "  print(user_pd['username'].values[0])\n",
        "  df_total_usernames.loc[count, 'username'] = user_pd['username'].values[0]\n",
        "  df_total_usernames.loc[count, 'total_enrollments'] = user_pd.shape[0]\n",
        "  df_total_usernames.loc[count, 'drop_rate'] = (user_pd[user_pd['label'] == 1].shape[0]) / user_pd.shape[0]\n",
        "  df_total_usernames.loc[count, 'completion_rate'] = (user_pd[user_pd['label'] == 0].shape[0]) / user_pd.shape[0]\n",
        "  count += 1\n",
        "\n",
        "completion_rate = df_total_usernames.merge(enrollment_data, left_on='username', right_on='username', how='inner')[['enrollment_id', 'drop_rate', 'completion_rate']]\n",
        "\n",
        "completion_rate.to_csv('generated/individual_completion_rate.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of5iUXciU_--",
        "colab_type": "text"
      },
      "source": [
        "Finally, all generated csv's are merged to produce one final csv. This final csv is used for training and cross-validation to build the model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEPTJC_e28Lg",
        "colab_type": "code",
        "outputId": "eeda41e3-ac1f-4379-eb3a-332e760f5c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Merge columns\n",
        "\n",
        "active_days = pd.read_csv('generated/active_days.csv')\n",
        "completion_rate_for_courses = pd.read_csv('generated/completion_rate_for_courses.csv')\n",
        "\n",
        "merge1 = active_days.merge(completion_rate_for_courses, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "\n",
        "extracted_category = pd.read_csv('generated/extracted_category.csv')\n",
        "merge2 = merge1.merge(extracted_category, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "\n",
        "individual_completion_rate = pd.read_csv('generated/individual_completion_rate.csv')\n",
        "merge3 = merge2.merge(individual_completion_rate, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "\n",
        "number_of_course = pd.read_csv('generated/number_of_course.csv')\n",
        "merge4 = merge3.merge(number_of_course, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "\n",
        "# #FIX this to percentage of modules\n",
        "number_of_module = pd.read_csv('generated/number_of_module.csv')\n",
        "merge5 = merge4.merge(number_of_module, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "number_of_users_per_course= pd.read_csv('generated/number_of_users_per_course.csv')\n",
        "merge6 = merge5.merge(number_of_users_per_course, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "time_data = pd.read_csv('generated/time_data.csv')\n",
        "merge7 = merge6.merge(time_data, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "time_data_less_than_60 = pd.read_csv('generated/time_data_60.csv')\n",
        "merge8 = merge7.merge(time_data_less_than_60, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "parallel_enrollments = pd.read_csv('generated/parallel_enrollments.csv')\n",
        "merge9 = merge8.merge(parallel_enrollments, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "week_counts = pd.read_csv('generated/wk_cnts.csv')\n",
        "merge10 = merge9.merge(week_counts, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "encoded_courses = pd.read_csv('generated/encoded_course.csv')\n",
        "merge11 = merge10.merge(encoded_courses, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "daily_activity_count = pd.read_csv('generated/daily_cnts.csv')\n",
        "merge12 = merge11.merge(daily_activity_count, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "week_sessions_count = pd.read_csv('generated/wk_session_cnts.csv')\n",
        "merge13 = merge12.merge(week_sessions_count, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "module_percentage_count = pd.read_csv('generated/percentage_of_module.csv')\n",
        "merge14 = merge13.merge(module_percentage_count, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "merge14.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72395, 132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30f8Ml3BV-aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merge14.to_csv('merged/finalData.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BiQ9nm9WleU",
        "colab_type": "code",
        "outputId": "5f92f0b5-c4d7-4f1a-f715-901e41e1a2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  data = pd.read_csv('merged/finalData.csv')\n",
        "  data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72395, 132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWPqUL1S61oL",
        "colab_type": "text"
      },
      "source": [
        "Test related features that are derived from Train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2OG32ZT67Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/MLProject/submissions/originalData')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUfpcEIn7Bqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf test.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rlHiC167KIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/MLProject/submissions/originalData/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIUjxmEi7Rpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ5vFwJu8rQf",
        "colab_type": "text"
      },
      "source": [
        "Generation of course completion rate csv for test from train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlIkNcm98aEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_course_completion_rate = pd.read_csv('/content/MLProject/submissions/originalData/train/generated/completion_rate_for_courses.csv')\n",
        "train_enrollment = pd.read_csv('/content/MLProject/submissions/originalData/train/enrollment_train.csv')\n",
        "\n",
        "train_merged = train_enrollment.merge(train_course_completion_rate, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "completion_by_courses = pd.DataFrame({'course_id':train_merged.course_id.unique()})\n",
        "completion_by_courses['overall_course_completion_rate'] = [list(set(train_merged['overall_course_completion_rate'].loc[train_merged['course_id'] == x['course_id']]))[0]\n",
        "    for _, x in completion_by_courses.iterrows()]\n",
        "\n",
        "\n",
        "test_enrollment = pd.read_csv('/content/MLProject/submissions/originalData/test/enrollment_train.csv')\n",
        "test_enrollment_course_completion = test_enrollment.merge(completion_by_courses, left_on='course_id', right_on='course_id', how='inner')[['enrollment_id', 'overall_course_completion_rate']]\n",
        "test_enrollment_course_completion.to_csv('/content/MLProject/submissions/originalData/test/generated/completion_rate_for_courses.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TamiPhYERqM",
        "colab_type": "text"
      },
      "source": [
        "Generation of individual completion rate csv for test from train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldlLJvcY81VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_individual_completion_rate = pd.read_csv('/content/MLProject/submissions/originalData/train/generated/individual_completion_rate.csv')\n",
        "train_enrollment = pd.read_csv('/content/MLProject/submissions/originalData/train/enrollment_train.csv')\n",
        "\n",
        "train_merged = train_enrollment.merge(train_individual_completion_rate, left_on='enrollment_id', right_on='enrollment_id', how='inner')\n",
        "\n",
        "\n",
        "usernames = pd.DataFrame({'username':train_merged.username.unique()})\n",
        "\n",
        "usernames['drop_rate'] = [list(set(train_merged['drop_rate'].loc[train_merged['username'] == x['username']]))[0] \n",
        "    for _, x in usernames.iterrows()]\n",
        "\n",
        "usernames['completion_rate'] = [list(set(train_merged['completion_rate'].loc[train_merged['username'] == x['username']]))[0]\n",
        "    for _, x in usernames.iterrows()]\n",
        "\n",
        "\n",
        "test_enrollment = pd.read_csv('/content/MLProject/submissions/originalData/test/enrollment_train.csv')\n",
        "\n",
        "merge_with_completion = test_enrollment.merge(usernames, left_on='username', right_on='username', how='left')\n",
        "\n",
        "# merge_with_completion = merge_with_completion.fillna(0.5)\n",
        "# merge_with_completion\n",
        "\n",
        "\n",
        "merge_with_completion.isnull().sum()\n",
        "merge_with_completion['completion_rate'].value_counts()\n",
        "\n",
        "mean_completion_rate = merge_with_completion['completion_rate'].mean(skipna = True) \n",
        "\n",
        "mean_drop_rate = merge_with_completion['drop_rate'].mean(skipna = True) \n",
        "\n",
        "merge_with_completion[['completion_rate']] = merge_with_completion[['completion_rate']].fillna(mean_completion_rate)\n",
        "merge_with_completion[['drop_rate']] = merge_with_completion[['drop_rate']].fillna(mean_drop_rate)\n",
        "\n",
        "\n",
        "final_merge_with_filled_values = merge_with_completion[['enrollment_id', 'drop_rate', 'completion_rate']]\n",
        "\n",
        "final_merge_with_filled_values.to_csv('/content/MLProject/submissions/originalData/test/generated/individual_completion_rate.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}